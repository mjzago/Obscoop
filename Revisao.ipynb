{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis da busca no Web of Science ['Publication Type', 'Authors', 'Book Authors', 'Book Editors', 'Book Group Authors', 'Author Full Names', 'Book Author Full Names', 'Group Authors', 'Article Title', 'Source Title', 'Book Series Title', 'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title', 'Conference Date', 'Conference Location', 'Conference Sponsor', 'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract', 'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses', 'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred', 'Funding Text', 'Cited References', 'Cited Reference Count', 'Times Cited, WoS Core', 'Times Cited, All Databases', '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher', 'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN', 'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date', 'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement', 'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page', 'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date', 'Number of Pages', 'WoS Categories', 'Web of Science Index', 'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations', 'Highly Cited Status', 'Hot Paper Status', 'Date of Export', 'UT (Unique WOS ID)', 'Web of Science Record']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Especifique o caminho completo do arquivo CSV\n",
    "arquivo_flavia = 'Revisão sistemática/WOSartigos.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(arquivo_flavia, nrows=10, encoding='ISO-8859-1')\n",
    "    # Obtenha os nomes das colunas em uma lista\n",
    "    colunas = df.columns.tolist()\n",
    "    # Exiba a lista de nomes das colunas\n",
    "    print(f\"Variáveis da busca no Web of Science\", colunas)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome do arquivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de 'Article Titles' na Busca da Flávia: 1228\n"
     ]
    }
   ],
   "source": [
    "arquivo_flavia = 'Revisão sistemática/WOSartigos.csv'\n",
    "\n",
    "try:\n",
    "    # Use o método read_csv do pandas para ler o arquivo CSV com a codificação ISO-8859-1\n",
    "    df = pd.read_csv(arquivo_flavia, encoding='ISO-8859-1')\n",
    "\n",
    "    # Conte quantos valores não nulos existem na coluna \"Article Title\"\n",
    "    total_article_titles = df['Article Title'].count()\n",
    "\n",
    "    print(f\"Total de 'Article Titles' na busca da Flávia: {total_article_titles}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome do arquivo CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis do arquivo scopus.csv ['ï»¿\"Authors\"', 'Author full names', 'Author(s) ID', 'Title', 'Year', 'Source title', 'Volume', 'Issue', 'Art. No.', 'Page start', 'Page end', 'Page count', 'Cited by', 'DOI', 'Link', 'Affiliations', 'Authors with affiliations', 'Abstract', 'Author Keywords', 'Index Keywords', 'Molecular Sequence Numbers', 'Chemicals/CAS', 'Tradenames', 'Manufacturers', 'Funding Details', 'Funding Texts', 'References', 'Correspondence Address', 'Editors', 'Publisher', 'Sponsors', 'Conference name', 'Conference date', 'Conference location', 'Conference code', 'ISSN', 'ISBN', 'CODEN', 'PubMed ID', 'Language of Original Document', 'Abbreviated Source Title', 'Document Type', 'Publication Stage', 'Open Access', 'Source', 'EID']\n"
     ]
    }
   ],
   "source": [
    "# Especifique o caminho completo do arquivo CSV (scopus.csv)\n",
    "arquivo_elisangela = 'Revisão sistemática/scopus.csv'\n",
    "\n",
    "try:\n",
    "    # Use o método read_csv do pandas para ler o arquivo CSV com a codificação ISO-8859-1\n",
    "    df = pd.read_csv(arquivo_elisangela, nrows=10, encoding='ISO-8859-1')\n",
    "\n",
    "    # Obtenha os nomes das colunas em uma lista\n",
    "    colunas = df.columns.tolist()\n",
    "\n",
    "    # Exiba a lista de nomes das colunas\n",
    "    print(f\"Variáveis do arquivo scopus.csv\", colunas)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome do arquivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de 'Title' no arquivo scopus.csv da Elisangela: 1520\n"
     ]
    }
   ],
   "source": [
    "# Especifique o caminho completo do arquivo CSV (scopus.csv)\n",
    "arquivo_elisangela = 'Revisão sistemática/scopus.csv'\n",
    "\n",
    "try:\n",
    "    # Use o método read_csv do pandas para ler o arquivo CSV com a codificação ISO-8859-1\n",
    "    df = pd.read_csv(arquivo_elisangela, encoding='ISO-8859-1')\n",
    "\n",
    "    # Conte quantos valores não nulos existem na coluna \"Title\"\n",
    "    total_titles = df['Title'].count()\n",
    "\n",
    "    print(f\"Total de 'Title' no arquivo scopus.csv da Elisangela: {total_titles}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome do arquivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparação entre 'Article Titles' da Flávia e 'Title' da Elisangela:\n",
      "Quantidade de duplicatas na Flávia: 1\n",
      "Quantidade de duplicatas na Elisangela: 5\n",
      "Quantidade de arquivos sem repetição na Flávia: 1227\n",
      "Quantidade de arquivos sem repetição na Elisangela: 1515\n"
     ]
    }
   ],
   "source": [
    "# Especifique os caminhos completos dos arquivos CSV\n",
    "arquivo_flavia = 'Revisão sistemática/WOSartigos.csv'\n",
    "arquivo_elisangela = 'Revisão sistemática/scopus.csv'\n",
    "\n",
    "try:\n",
    "    # Use o método read_csv do pandas para ler os arquivos CSV com a codificação ISO-8859-1\n",
    "    df_flavia = pd.read_csv(arquivo_flavia, encoding='ISO-8859-1')\n",
    "    df_elisangela = pd.read_csv(arquivo_elisangela, encoding='ISO-8859-1')\n",
    "\n",
    "    # Selecione as colunas relevantes para a comparação\n",
    "    coluna_flavia = 'Article Title'\n",
    "    coluna_elisangela = 'Title'\n",
    "\n",
    "    # Elimine as duplicatas em ambos os DataFrames\n",
    "    df_flavia_sem_duplicatas = df_flavia.drop_duplicates(subset=[coluna_flavia])\n",
    "    df_elisangela_sem_duplicatas = df_elisangela.drop_duplicates(subset=[coluna_elisangela])\n",
    "\n",
    "    # Conte a quantidade de duplicatas em ambos os DataFrames\n",
    "    quantidade_duplicatas_flavia = df_flavia.shape[0] - df_flavia_sem_duplicatas.shape[0]\n",
    "    quantidade_duplicatas_elisangela = df_elisangela.shape[0] - df_elisangela_sem_duplicatas.shape[0]\n",
    "\n",
    "    # Conte quantos arquivos sem repetição existem\n",
    "    quantidade_sem_repeticao_flavia = df_flavia_sem_duplicatas.shape[0]\n",
    "    quantidade_sem_repeticao_elisangela = df_elisangela_sem_duplicatas.shape[0]\n",
    "\n",
    "    print(f\"Comparação entre 'Article Titles' da Flávia e 'Title' da Elisangela:\")\n",
    "    print(f\"Quantidade de duplicatas na Flávia: {quantidade_duplicatas_flavia}\")\n",
    "    print(f\"Quantidade de duplicatas na Elisangela: {quantidade_duplicatas_elisangela}\")\n",
    "    print(f\"Quantidade de arquivos sem repetição na Flávia: {quantidade_sem_repeticao_flavia}\")\n",
    "    print(f\"Quantidade de arquivos sem repetição na Elisangela: {quantidade_sem_repeticao_elisangela}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome dos arquivos CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparação entre as bases da Flávia e da Elisangela:\n",
      "Quantidade de entradas comuns: 375\n",
      "Quantidade de entradas exclusivas da Flávia: 853\n",
      "Quantidade de entradas exclusivas da Elisangela: 1146\n",
      "Total de artigos exclusivos: 2374\n"
     ]
    }
   ],
   "source": [
    "# Especifique os caminhos completos dos arquivos CSV\n",
    "arquivo_flavia = 'Revisão sistemática/WOSartigos.csv'\n",
    "arquivo_elisangela = 'Revisão sistemática/scopus.csv'\n",
    "\n",
    "try:\n",
    "    # Use o método read_csv do pandas para ler os arquivos CSV com a codificação ISO-8859-1\n",
    "    df_flavia = pd.read_csv(arquivo_flavia, encoding='ISO-8859-1')\n",
    "    df_elisangela = pd.read_csv(arquivo_elisangela, encoding='ISO-8859-1')\n",
    "\n",
    "    # Selecione as colunas relevantes para a comparação\n",
    "    coluna_flavia = 'Article Title'\n",
    "    coluna_elisangela = 'Title'\n",
    "\n",
    "    # Realize a mesclagem dos DataFrames com base nas colunas selecionadas\n",
    "    # Use how='outer' para incluir todas as entradas de ambos os DataFrames\n",
    "    merged_data = pd.merge(df_flavia, df_elisangela, left_on=coluna_flavia, right_on=coluna_elisangela, how='outer', indicator=True)\n",
    "\n",
    "    # Separe as entradas em três grupos: comuns, exclusivas da Flávia e exclusivas da Elisangela\n",
    "    comuns = merged_data[merged_data['_merge'] == 'both']\n",
    "    exclusivas_flavia = merged_data[merged_data['_merge'] == 'left_only']\n",
    "    exclusivas_elisangela = merged_data[merged_data['_merge'] == 'right_only']\n",
    "\n",
    "    # Conte o número de entradas em cada grupo\n",
    "    quantidade_comuns = comuns.shape[0]\n",
    "    quantidade_exclusivas_flavia = exclusivas_flavia.shape[0]\n",
    "    quantidade_exclusivas_elisangela = exclusivas_elisangela.shape[0]\n",
    "\n",
    "    # Calcule o número total de artigos exclusivos\n",
    "    total_exclusivos = quantidade_exclusivas_flavia + quantidade_exclusivas_elisangela + quantidade_comuns\n",
    "\n",
    "    print(f\"Comparação entre as bases da Flávia e da Elisangela:\")\n",
    "    print(f\"Quantidade de entradas comuns: {quantidade_comuns}\")\n",
    "    print(f\"Quantidade de entradas exclusivas da Flávia: {quantidade_exclusivas_flavia}\")\n",
    "    print(f\"Quantidade de entradas exclusivas da Elisangela: {quantidade_exclusivas_elisangela}\")\n",
    "    print(f\"Total de artigos exclusivos: {total_exclusivos}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o caminho e o nome dos arquivos CSV.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
